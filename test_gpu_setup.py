#!/usr/bin/env python3
"""
Test script to verify GPU setup works safely
This script tests the new GPU features without affecting your current setup
"""
import os
import sys
import logging
from pathlib import Path

# Add current directory to path
sys.path.insert(0, str(Path(__file__).parent))

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_environment_detection():
    """Test environment detection"""
    print("ğŸ” Testing Environment Detection...")
    
    try:
        from config import config
        summary = config.get_summary()
        
        print(f"âœ… Environment: {summary['environment']}")
        print(f"âœ… CPU Count: {summary['cpu_count']}")
        print(f"âœ… GPU Available: {summary['gpu_available']}")
        print(f"âœ… GPU Count: {summary['gpu_count']}")
        print(f"âœ… Whisper Backend: {summary['whisper_backend']}")
        print(f"âœ… Max Workers: {summary['max_workers']}")
        
        return True
    except Exception as e:
        print(f"âŒ Environment detection failed: {e}")
        return False

def test_whisper_wrapper():
    """Test Whisper wrapper without GPU"""
    print("\nğŸ¤ Testing Whisper Wrapper (CPU mode)...")
    
    try:
        # Force CPU mode for testing
        os.environ['USE_GPU'] = 'false'
        
        from whisper_wrapper import get_whisper_model
        whisper_model = get_whisper_model()
        
        info = whisper_model.get_info()
        print(f"âœ… Backend: {info['backend']}")
        print(f"âœ… GPU Enabled: {info['gpu_enabled']}")
        print(f"âœ… Model Loaded: {info['model_loaded']}")
        
        if info['backend'] == 'openai-whisper':
            print("âœ… Using your current working CPU setup")
        
        return True
    except Exception as e:
        print(f"âŒ Whisper wrapper test failed: {e}")
        return False

def test_gpu_requirements():
    """Test if GPU requirements are available"""
    print("\nğŸš€ Testing GPU Requirements...")
    
    try:
        # Test PyTorch
        try:
            import torch
            print(f"âœ… PyTorch available: {torch.__version__}")
            print(f"âœ… CUDA available: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                print(f"âœ… CUDA devices: {torch.cuda.device_count()}")
        except ImportError:
            print("â„¹ï¸ PyTorch not installed (normal for CPU-only setup)")
        
        # Test faster-whisper
        try:
            from faster_whisper import WhisperModel
            print("âœ… faster-whisper available")
        except ImportError:
            print("â„¹ï¸ faster-whisper not installed (normal for CPU-only setup)")
        
        return True
    except Exception as e:
        print(f"âŒ GPU requirements test failed: {e}")
        return False

def test_docker_files():
    """Test if Docker files are properly created"""
    print("\nğŸ³ Testing Docker Files...")
    
    files_to_check = [
        'Dockerfile.gpu',
        'docker-compose.gpu.yml',
        'requirements-gpu.txt',
        'k8s/deployment.yaml',
        'k8s/service.yaml',
        'k8s/pvc.yaml'
    ]
    
    all_good = True
    for file in files_to_check:
        if Path(file).exists():
            print(f"âœ… {file} exists")
        else:
            print(f"âŒ {file} missing")
            all_good = False
    
    return all_good

def main():
    """Run all tests"""
    print("ğŸ§ª GPU Setup Safety Test")
    print("=" * 50)
    
    tests = [
        ("Environment Detection", test_environment_detection),
        ("Whisper Wrapper", test_whisper_wrapper),
        ("GPU Requirements", test_gpu_requirements),
        ("Docker Files", test_docker_files)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} crashed: {e}")
            results.append((test_name, False))
    
    print("\nğŸ“Š Test Results:")
    print("=" * 50)
    
    passed = 0
    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} {test_name}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ {passed}/{len(results)} tests passed")
    
    if passed == len(results):
        print("ğŸ‰ All tests passed! Your setup is safe and ready for GPU deployment.")
    else:
        print("âš ï¸ Some tests failed, but your current setup should still work.")
    
    print("\nğŸ’¡ Next steps:")
    print("1. Your current setup (docker-compose.yml) is unchanged and safe")
    print("2. For GPU testing: USE_GPU=true python test_gpu_setup.py")
    print("3. For H100 deployment: Use docker-compose.gpu.yml")

if __name__ == "__main__":
    main() 