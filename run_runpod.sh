#!/bin/bash

echo "üöÄ Starting Monaco Telecom Audio Analysis on RunPod H100"

# Configuration GPU
export USE_GPU=true
export CUDA_VISIBLE_DEVICES=0
export SKIP_DIARIZATION=false
export MAX_WORKERS=10
export OLLAMA_URL=http://localhost:11434/api/generate
export OLLAMA_MODEL=llama3.1:latest

# V√©rifications
echo "üìä GPU Check:"
nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv

echo "üîß Python Environment:"
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')" 2>/dev/null || echo "PyTorch not installed yet"

# Installation d√©pendances si n√©cessaire
if [ ! -f "requirements_installed.flag" ]; then
    echo "üì¶ Installing requirements..."
    pip install -r requirements-gpu.txt
    touch requirements_installed.flag
    echo "‚úÖ Requirements installed"
else
    echo "‚úÖ Requirements already installed"
fi

# V√©rification post-installation
echo "üß™ Post-install verification:"
python -c "
import torch
print(f'PyTorch CUDA: {torch.cuda.is_available()}')
try:
    from faster_whisper import WhisperModel
    print('‚úÖ faster-whisper available')
except ImportError as e:
    print(f'‚ùå faster-whisper import failed: {e}')
try:
    from pyannote.audio import Pipeline
    print('‚úÖ pyannote.audio available')
except ImportError as e:
    print(f'‚ùå pyannote.audio import failed: {e}')
"

# D√©marrage Ollama en arri√®re-plan
if ! pgrep -f "ollama" > /dev/null; then
    echo "ü§ñ Starting Ollama..."
    if command -v ollama &> /dev/null; then
        ollama serve &
        sleep 5
        ollama pull llama3.1:latest 2>/dev/null || echo "‚ö†Ô∏è  Ollama model pull failed, continuing without it"
    else
        echo "‚ö†Ô∏è  Ollama not found, continuing without it"
    fi
else
    echo "‚úÖ Ollama already running"
fi

# D√©marrage application
echo "üéØ Starting FastAPI application..."
echo "Environment variables:"
echo "- USE_GPU: $USE_GPU"
echo "- SKIP_DIARIZATION: $SKIP_DIARIZATION"
echo "- MAX_WORKERS: $MAX_WORKERS"

echo "üîß Diagnostic et r√©solution cuDNN automatique..."
python fix_cudnn_gpu.py

if [ $? -eq 0 ]; then
    echo "‚úÖ cuDNN r√©solu avec succ√®s!"
    echo "üöÄ D√©marrage application Monaco Telecom sur RunPod H100..."
    python app.py
else
    echo "‚ùå √âchec r√©solution cuDNN - d√©marrage en mode CPU de secours"
    export USE_GPU=false
    python app.py
fi 